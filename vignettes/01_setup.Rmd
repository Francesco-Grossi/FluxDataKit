---
title: "Setup and data provenance"
author: "Koen Hufkens"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Setup and data provenance}
  %\VignetteEngine{knitr::rmarkdown}
  %\usepackage[utf8]{inputenc}
---

# Setup

To setup the project first clone the git repository

```r
git clone https://github.com/computationales/flux_data_kit.git
```

and install all critical packages required in gathering and processing the data.

```r
install.packages(
  c(
    "devtools",
    "rvest",
    "tidyverse",
    "icoscp",
    "RCurl",
    "XML",
    "amerifluxr",
    "raster",
    "MODISTools"
  )
)

devtools::install_github(
  "computationales/ingestr"
)

devtools::install_github(
  "computationales/rsofun"
)
```

With all tools installed we need to download the required input data for
aggregation.

# data provenance (downloads)

A list of numbered scripts is provided in the `data-raw` directory which govern
the downloading and compiling of intermediate data. The numbered scripts should
be run in sequence.

Due to login-walls, or missing API infrastructure, most data downloads are still
manual instead of automated. The below section therefore links to the locations
where you can manually get the data. No fixes will be provided to facilitate this
process further.

By default the data will be downloaded to a directory with the `data-raw/`
base path. Before running any scripts, check if data is written to this directory.
When you want to alter the storage location you may use soft links.

## Meta data

Meta-data is compiled on a site by site basis using the
`01_collect_meta-data.R` script. This will compile all easily available
meta-data through either API calls or scraping the data downloaded in the
previous step (setup / data collection).

```r
source("data-raw/01_collect_meta-data.R")
```

Given the various datasets, and at times overlap between the datasets a priority
in processing is given to more recent (hopefully) and more complete datasets. In
order of processing this means that OneFlux has priority over FLUXNET2015, and 
Plumber2. ICOS data has priority over FLUXNET2015 for European sites. Overall, 
Plumber2 mostly fills in the remaining sites in Asia and Australia. The final
picking order is thus:

```r
source("data-raw/02_compile_final_site_list.R")
```

## Flux data

All ecosystem flux sources should be downloaded at half-hourly (HH) rates, unless
otherwise specified. Data sources and final paths are listed below. Top level
paths for flux data are considered to be sufficient for further processing.

Estimated data sizes are provided to indicate network load, although for most
these downloads should be easily manageable from a download and storage perspective.
Below you find a summary table of data volumes, nr. of sites and the local storage
paths for all flux data products considered.

| product   |      data volume      |  nr. sites |  data path |
|----------|:-------------:|:------:|:------|
| FLUXNET2015 |  ~35GB | 166 | `data-raw/flux_data/fluxnet2015/`
| ICOS | ~12GB   |  67  | `data-raw/flux_data/icos/`
| OneFlux | ~12GB | 74 | `data-raw/flux_data/oneflux/`
| Plumber2 | ~4GB | 112 | `data-raw/flux_data/plumber_fluxnet/`

### FLUXNET2015

FLUXNET2015 data is downloaded from the dedicated 
[download page](https://fluxnet.org/data/fluxnet2015-dataset/). A login is 
required to access the data. We only considered the legacy **FULLSET** data, 
which is covered by a CC-BY 4.0 license. This limits the site count. Expanding 
this list is possible, but only with permission from the PI sharing the data. 
We refer to the [data policy](https://fluxnet.org/data/data-policy/) for more
details.

### ICOS

As of writing ICOS data was provided as a pre-release to our group and is therefore not
yet available for a wider public. However, this data should be released shortly through
the [ICOS carbon portal](https://www.icos-cp.eu/data-services/about-data-portal).

### OneFlux

A limited set of sites has been reprocessed using the OneFlux processing chain. This
beta release can be found (here)[https://ameriflux.lbl.gov/data/download-data-oneflux-beta/].
Over time a full dataset will supersede the FLUXNET2015 data. However, now the 
site count is limited.

### Plumber2

"PLUMBER2 is a model intercomparison project for land surface models. Multiple 
leading land surface and ecosystem models are evaluated for water and carbon fluxes
at 170 flux tower sites, spanning multiple biomes and climate zones globally." 
the full description of the dataset can be found in the publication by 
[Ukkola et al. 2021](https://doi.org/10.5194/essd-2021-181) and combines 
FLUXNET2015, La Thuile and OzFlux collections.

The downloading and conversion is facilitated using a script 
`00_download_convert_flux_data.R` included in the `data-raw` directory.

## Gridded products

Other gridded data products are required to complement the flux data for modelling
purposes. Products required, data volumes and storage paths are listed below.
Detailed links to original publications and data are provided below.

| product   |      data volume      |  data path |
|-----------|:---------------------:|:-----------|
| rooting zone water storage |  ~80MB | `data-raw/ancillary_data/cwdx80/`
| Koeppen-Geiger |  ~22MB | `data-raw/ancillary_data/koeppen_geiger/`
| field capacity |  ~4MB | `data-raw/ancillary_data/field_capacity/`

### Rooting zone water storage capacity

Global rooting zone water storage capacity can be
[downloaded here](https://zenodo.org/record/5515246).

### Koeppen-Geiger (included in repo)

Koeppen-Geiger climate classifications are downloaded from the recent
work by [Beck et al. 2018](https://www.nature.com/articles/sdata2018214). Data
can be downloaded from the [project website](http://www.gloh2o.org/koppen/) but
is also included in the repository due to its small size.

### Field capacity (included in repo)

Koeppen-Geiger climate classifications are downloaded from the recent
work by [Beck et al. 2018](https://www.nature.com/articles/sdata2018214). Data
can be downloaded from the [project website](http://www.gloh2o.org/koppen/) but
is also included in the repository due to its small size.

## Remote sensing data

We include various MODIS products to complement the flux data. Data are downloaded
from Google Earth Engine (GEE) using the gee_subset python toolkit using the {ingestr}
package. Data are stored in a product by product basis. in the `data-raw/modis/`
directory. Data is downloaded using the `02_download_modis_data.R` script and
raw data stored in `data-raw/modis/raw`.

Note that downloading this data requires a functioning GEE API instance on your
computer. For setup instructions we refer to [the GEE docs](https://developers.google.com/earth-engine/guides/python_install).

> Note that you will need to compile the meta-data list first 
(see meta-data article).

| product   |      data volume      |  data path |
|-----------|:---------------------:|:-----------|
| MODXXX |  ~7GB | `data-raw/modis/raw/`


Below you find a table of all downloaded data products we consider relevant
within the context of model development. These might be expanded over time.

| product   |      band      |  multiplier |
|-----------|:---------------------|:-----------|
| [MCD15A3H](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MCD15A3H#bands) |  Fpar | 0.01
| [MCD15A3H](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MCD15A3H#bands) |  Lai | 0.1
| [MOD15A2H](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD15A2H) | Fpar_500m | 0.01 
| [MOD15A2H](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD15A2H) | Lai_500m | 0.1 
| [MOD17A2H](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MOD17A2H) | Gpp | 0.0001 
| [MOD11A1](https://developers.google.com/earth-engine/datasets/catalog/MODIS_061_MOD11A1) | LST_Day_1km | 0.02
| [MCD43A4](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MCD43A4) | Nadir_Reflectance_Band(1-7) | 0.0001 
| [MODOCGA](https://developers.google.com/earth-engine/datasets/catalog/MODIS_006_MODOCGA) | sur_refl_b(08-15) | 0.0001

Data is subsequently compiled into a consistent tidy format organized by site
name and stored in `data/modis_data.rds` using the `05_combine_modis_data.R` 
script. For details on the products we refer to the links in the table above.
